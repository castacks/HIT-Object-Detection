{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e49e4d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrew/.mambaforge/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/andrew/.mambaforge/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c104cuda20CUDACachingAllocator9allocatorE'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch_tensorrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b08ba490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_file_name='andrew_desktop_HIT+WIT_550_checkpoint_ssd300_state_dict.torchscript'\n"
     ]
    }
   ],
   "source": [
    "ssd_checkpoint_file = \"/home/andrew/Development/wildfire/WIT-Asset-Detection/ssd_logs/2023_03_01__13_42_11/andrew_desktop_HIT+WIT_550_checkpoint_ssd300_state_dict.pt\"\n",
    "output_file_name = (\n",
    "    os.path.splitext(os.path.basename(ssd_checkpoint_file))[0] + \".torchscript\"\n",
    ")\n",
    "print(f\"{output_file_name=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e55536b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded checkpoint from epoch 551.\n",
      "\n",
      "\n",
      "Loaded base model.\n",
      "\n",
      "tensor([[0.0132, 0.0132, 0.1000, 0.1000],\n",
      "        [0.0132, 0.0132, 0.1414, 0.1414],\n",
      "        [0.0132, 0.0132, 0.1414, 0.0707],\n",
      "        ...,\n",
      "        [0.5000, 0.5000, 1.0000, 1.0000],\n",
      "        [0.5000, 0.5000, 1.0000, 0.6364],\n",
      "        [0.5000, 0.5000, 0.6364, 1.0000]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SSD300(\n",
       "  (base): VGGBase(\n",
       "    (conv1_1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv1_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv2_1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv2_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv3_1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv3_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv3_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (conv4_1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv4_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv4_3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv5_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv5_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv5_3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (pool5): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "    (conv6): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
       "    (conv7): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (aux_convs): AuxiliaryConvolutions(\n",
       "    (conv8_1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv8_2): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (conv9_1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv9_2): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (conv10_1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv10_2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (conv11_1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv11_2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "  )\n",
       "  (pred_convs): PredictionConvolutions(\n",
       "    (loc_conv4_3): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (loc_conv7): Conv2d(1024, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (loc_conv8_2): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (loc_conv9_2): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (loc_conv10_2): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (loc_conv11_2): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (cl_conv4_3): Conv2d(512, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (cl_conv7): Conv2d(1024, 42, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (cl_conv8_2): Conv2d(512, 42, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (cl_conv9_2): Conv2d(256, 42, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (cl_conv10_2): Conv2d(256, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (cl_conv11_2): Conv2d(256, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(ssd_checkpoint_file)\n",
    "start_epoch = checkpoint[\"epoch\"] + 1\n",
    "print(\"\\nLoaded checkpoint from epoch %d.\\n\" % start_epoch)\n",
    "\n",
    "\n",
    "from ssd_model import SSD300\n",
    "from ssd_utils import label_map\n",
    "\n",
    "n_classes = len(label_map)\n",
    "model = SSD300(n_classes=n_classes)\n",
    "\n",
    "model.load_state_dict(checkpoint[\"model\"])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70822745",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import HITUAVDatasetTrain, HITUAVDatasetVal, WITUAVDataset, CombinedDataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import albumentations as A\n",
    "\n",
    "image_transform = A.Compose(\n",
    "    [\n",
    "        # Randomly rotate the image and bounding boxes\n",
    "        A.RandomRotate90(),\n",
    "        # Randomly flip the image and bounding boxes horizontally\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        # Randomly flip the image and bounding boxes vertically\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        # Apply a color jitter to the image\n",
    "        A.ColorJitter(p=0.5),\n",
    "        # Apply CLAHE to the image\n",
    "        A.CLAHE(clip_limit=(1, 4), p=0.5),\n",
    "        # Add random noise to the image\n",
    "        A.GaussNoise(var_limit=(10.0, 50.0), p=0.5),\n",
    "        # Add a grid of lines to the image\n",
    "        A.GridDistortion(p=0.5),\n",
    "        # Randomly change brightness, contrast and saturation\n",
    "        A.RandomBrightnessContrast(p=0.5),\n",
    "        A.RandomGamma(p=0.5),\n",
    "        A.HueSaturationValue(p=0.5),\n",
    "        # Add a black rectangle to the image\n",
    "        A.RandomShadow(\n",
    "            p=0.5, num_shadows_lower=1, num_shadows_upper=3, shadow_dimension=3\n",
    "        ),\n",
    "        A.RandomResizedCrop(\n",
    "            height=300,\n",
    "            width=300,\n",
    "            scale=(0.8, 1.0),\n",
    "            ratio=(0.75, 1.3333333333333333),\n",
    "            p=1.0,\n",
    "        ),\n",
    "        A.Perspective(),\n",
    "    ],\n",
    "    # HIT dataset is in unnormalized YOLO format, which is x_center, y_center, width, height.\n",
    "    # however for SSD it transforms it to pascal_voc format\n",
    "    bbox_params=A.BboxParams(format=\"pascal_voc\", label_fields=[\"labels\"]),\n",
    ")\n",
    "\n",
    "train_dataset = WITUAVDataset(\n",
    "    root=\"./WIT-UAV-Dataset_split/train/\",\n",
    "    sensor=\"both\",\n",
    "    image_transform=image_transform,\n",
    ")\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    collate_fn=train_dataset.collate_fn,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    ")  # note that we're passing the collate function here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0aa758a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [Torch-TensorRT TorchScript Conversion Context] - CUDA lazy loading is not enabled. Enabling it can significantly reduce device memory usage. See `CUDA_MODULE_LOADING` in https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#env-vars\n",
      "WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter\n",
      "WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter\n",
      "WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter\n",
      "WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter\n",
      "WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter\n",
      "WARNING: [Torch-TensorRT] - Sum converter disregards dtype\n",
      "WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size\n",
      "WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.6.0 but loaded cuDNN 8.5.0\n",
      "WARNING: [Torch-TensorRT] - CUDA lazy loading is not enabled. Enabling it can significantly reduce device memory usage. See `CUDA_MODULE_LOADING` in https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#env-vars\n"
     ]
    }
   ],
   "source": [
    "inputs = [\n",
    "    torch_tensorrt.Input(\n",
    "        min_shape=[1, 3, 300, 300],\n",
    "        opt_shape=[1, 3, 300, 300],\n",
    "        max_shape=[1, 3, 300, 300],\n",
    "        dtype=torch.half,\n",
    "    )\n",
    "]\n",
    "enabled_precisions = {torch.half}  # Run with fp16\n",
    "\n",
    "trt_ts_module = torch_tensorrt.compile(\n",
    "    model.half().cuda(), inputs=inputs, enabled_precisions=enabled_precisions\n",
    ")\n",
    "\n",
    "input_data = torch.random.randn\n",
    "input_data = next(iter(train_loader))[0]\n",
    "input_data = input_data.to(\"cuda\").half()\n",
    "result = trt_ts_module(input_data)\n",
    "torch.jit.save(\n",
    "    trt_ts_module, \"andrew_desktop_HIT+WIT_550_checkpoint_ssd300_trt_half.torchscript\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a102e8f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "a53bdd2ae0f00e481e05de05afde8125ef4fc0e50be032720b24d66c268f146b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
