{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e49e4d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b08ba490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_file_name='andrew_desktop_HIT+WIT_550_checkpoint_ssd300_state_dict.torchscript'\n"
     ]
    }
   ],
   "source": [
    "ssd_checkpoint_file = \"/home/andrew/Development/wildfire/WIT-Asset-Detection/ssd_logs/2023_03_01__13_42_11/andrew_desktop_HIT+WIT_550_checkpoint_ssd300_state_dict.pt\"\n",
    "output_file_name = (\n",
    "    os.path.splitext(os.path.basename(ssd_checkpoint_file))[0] + \".torchscript\"\n",
    ")\n",
    "print(f\"{output_file_name=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e55536b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded checkpoint from epoch 551.\n",
      "\n",
      "\n",
      "Loaded base model.\n",
      "\n",
      "tensor([[0.0132, 0.0132, 0.1000, 0.1000],\n",
      "        [0.0132, 0.0132, 0.1414, 0.1414],\n",
      "        [0.0132, 0.0132, 0.1414, 0.0707],\n",
      "        ...,\n",
      "        [0.5000, 0.5000, 1.0000, 1.0000],\n",
      "        [0.5000, 0.5000, 1.0000, 0.6364],\n",
      "        [0.5000, 0.5000, 0.6364, 1.0000]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SSD300(\n",
       "  (base): VGGBase(\n",
       "    (conv1_1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv1_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv2_1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv2_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv3_1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv3_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv3_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (conv4_1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv4_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv4_3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv5_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv5_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv5_3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (pool5): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "    (conv6): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
       "    (conv7): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (aux_convs): AuxiliaryConvolutions(\n",
       "    (conv8_1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv8_2): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (conv9_1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv9_2): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (conv10_1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv10_2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (conv11_1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv11_2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "  )\n",
       "  (pred_convs): PredictionConvolutions(\n",
       "    (loc_conv4_3): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (loc_conv7): Conv2d(1024, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (loc_conv8_2): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (loc_conv9_2): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (loc_conv10_2): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (loc_conv11_2): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (cl_conv4_3): Conv2d(512, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (cl_conv7): Conv2d(1024, 42, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (cl_conv8_2): Conv2d(512, 42, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (cl_conv9_2): Conv2d(256, 42, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (cl_conv10_2): Conv2d(256, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (cl_conv11_2): Conv2d(256, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(ssd_checkpoint_file)\n",
    "start_epoch = checkpoint[\"epoch\"] + 1\n",
    "print(\"\\nLoaded checkpoint from epoch %d.\\n\" % start_epoch)\n",
    "\n",
    "\n",
    "from ssd_model import SSD300\n",
    "from ssd_utils import label_map\n",
    "\n",
    "n_classes = len(label_map)\n",
    "model = SSD300(n_classes=n_classes)\n",
    "\n",
    "model.load_state_dict(checkpoint[\"model\"])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4c45989",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(profile=\"full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "167a22d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrew/.mambaforge/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import PIL.Image\n",
    "\n",
    "SSD_c, SSD_h, SSD_w = 3, 300, 300\n",
    "sample_image_input = torch.zeros(1, SSD_c, SSD_h, SSD_w)\n",
    "\n",
    "# image_file_path = \"/home/andrew/Downloads/thermal.png\"\n",
    "# image_file_path = \"/home/andrew/Downloads/black.png\"\n",
    "image_file_path = \"/home/andrew/Downloads/gray.png\"\n",
    "sample_image_input = PIL.Image.open(image_file_path)\n",
    "\n",
    "\n",
    "from torchvision.transforms.functional import to_tensor, normalize, resize\n",
    "\n",
    "sample_tensor = to_tensor(sample_image_input)\n",
    "sample_tensor = resize(sample_tensor, (SSD_h, SSD_w))\n",
    "sample_tensor = normalize(\n",
    "    sample_tensor, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    ").unsqueeze(0)\n",
    "sample_tensor.shape\n",
    "\n",
    "module = torch.jit.load(\n",
    "    \"/home/andrew/Development/ipp_ws/src/ipp_computer_vision/object_detection/config/wildfire/torchscript_models/andrew_desktop_HIT+WIT_550_checkpoint_ssd300_state_dict.torchscript\"\n",
    ")\n",
    "module.eval()\n",
    "predicted_locs, predicted_scores = module(sample_tensor)\n",
    "det_boxes, det_labels, det_scores = model.detect_objects(\n",
    "    predicted_locs, predicted_scores, min_score=0.2, max_overlap=0.5, top_k=200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0aa758a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Diagnostic Run torch.onnx.export version 2.0.0 ================\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = sample_tensor.cuda()\n",
    "\n",
    "torch.onnx.export(\n",
    "    model.cuda().eval(),\n",
    "    data,\n",
    "    os.path.splitext(os.path.basename(ssd_checkpoint_file))[0] + \".onnx\",\n",
    "    input_names=[\"input\"],\n",
    "    output_names=[\"output\"],\n",
    "    dynamic_axes={\"input\": {0: \"batch_size\"}, \"output\": {0: \"batch_size\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e449d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_script_module = torch.jit.trace(model, sample_image_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329b8010",
   "metadata": {},
   "source": [
    "Check the output make sure it's the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440289de",
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_output = traced_script_module(sample_image_input)\n",
    "print(traced_output[0].shape)\n",
    "print(traced_output[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26ab5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_output = model(sample_image_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab63720",
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66df1c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Norm=\", torch.norm(traced_output[0] - actual_output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a3c685",
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_script_module.save(output_file_name)\n",
    "print(\"Done! Output to:\", output_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccb27b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_module = torch.jit.load(output_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d435aad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_module(sample_tensor)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad65091",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "a53bdd2ae0f00e481e05de05afde8125ef4fc0e50be032720b24d66c268f146b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
